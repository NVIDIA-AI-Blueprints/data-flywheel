{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover More Cost-Efficient AI Customer Service Agents\n",
    "\n",
    "Learn how to use the Data Flywheel Foundational Blueprint to continuously discover and promote more cost-efficient variants of an [agentic customer service agent](https://build.nvidia.com/nvidia/ai-virtual-assistant-for-customer-service). \n",
    "\n",
    "The customer service agent in this tutorial uses tool calling to handle common service tasks, such as: \n",
    "\n",
    "- Product Q&A\n",
    "- Order status verification\n",
    "- Returns processing\n",
    "- Engaging in small talk\n",
    "\n",
    "These interactions generate logs and tool-calling data that you can use as both evaluation benchmarks and training data. In this tutorial, you'll use this information to drive the flywheel process, fine-tuning smaller LLMs (such as `meta/llama-3.2-1B-instruct`, `meta/llama-3.2-3B-instruct`, `meta/llama-3.1-8B-instruct`) to match accuracy of the currently deployed model (`meta/llama-3.3-70B-instruct`).\n",
    "\n",
    "## Interfacing with the Blueprint\n",
    "\n",
    "The following diagram illustrates how admin tools and applications interact with the Flywheel Blueprint, which orchestrates logging, processing, and model management to enable continuous optimization.\n",
    "\n",
    "![Arch](./arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents: \n",
    "\n",
    "0. [Prerequisites](#0)\n",
    "1. [Load Sample Data](#1)\n",
    "2. [Create a Flywheel Job](#2)\n",
    "3. [Monitor Job Status](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## Prerequisites\n",
    "\n",
    "### Setup\n",
    "\n",
    "Import required libraries and configure pandas display options for better readability in notebook outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)        # Width of the display in characters\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content of each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_DIR = Path.cwd().parent\n",
    "DATA_DIR = PARENT_DIR / \"data\"\n",
    "\n",
    "sys.path.insert(0, str(PARENT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Configurations and Health Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flywheel Orchestrator URL\n",
    "API_BASE_URL = \"http://0.0.0.0:8000\"\n",
    "\n",
    "# Workload identifiers\n",
    "WORKLOAD_ID = \"aiva-tool-calls\"\n",
    "CLIENT_ID = \"aiva-dfw-tutorial\"\n",
    "\n",
    "# Polling interval (in seconds) for monitoring flywheel job\n",
    "POLL_INTERVAL = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"1\"></a>\n",
    "## Step 1: Load Sample Data\n",
    "\n",
    "Use the provided sample dataset (`data/aiva-final.jsonl`) to simulate real user logs captured while an agentic customer service agent application is running. Each data point uses the OpenAI `ChatCompletions` request format and contains the following attributes:\n",
    "\n",
    "- `messages` include a `system` message as well as a `user` query.\n",
    "- `tools` includes a list of functions and parameters available to the LLM to choose from, as well as their parameters and descriptions.\n",
    "- `responses` are the response generated by the current model (`meta/llama-3.1-70b-instruct`). This response contains the function name(s) and associated argument(s) in a \"tool_calls\" dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = DATA_DIR / \"aiva_l1_dataset.jsonl\"\n",
    "\n",
    "!head -n1 {DATA_PATH} | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data points generated by the system in response to user queries are considered **ground truth**. \n",
    "\n",
    "Ground truth data points are used to **evaluate** and **customize** more efficient models that can perform similarly to the current model. This customization process is analogous to a student-teacher distillation setup, where synthetic data generated from the teacher model is used to fine-tune a student model.\n",
    "\n",
    "Next, we'll load the data into Elasticsearch using a helper method `load_data_to_elasticsearch`, making it accessible to the Flywheel Orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.scripts.load_test_data import load_data_to_elasticsearch\n",
    "\n",
    "load_data_to_elasticsearch(file_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"2\"></a>\n",
    "## Step 2: Create a Flywheel job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate a Flywheel job by sending a POST request to the `/jobs` API. This triggers the workflow asynchronously.\n",
    "\n",
    "In production environments, you can automate this process to run at scheduled intervals, in response to specific events, or on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    f\"{API_BASE_URL}/api/jobs\",\n",
    "    json={\"workload_id\": \"aiva_2\", \"client_id\": \"3434\"}\n",
    ")\n",
    "\n",
    "response.raise_for_status()\n",
    "job_id = response.json()[\"id\"]\n",
    "\n",
    "print(f\"Created job with ID: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"3\"></a>\n",
    "## Step 3: Monitor Job Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit a GET request to `/jobs/{job_id}` to retrieve the current status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_status(job_id):\n",
    "    \"\"\"Get the current status of a job.\"\"\"\n",
    "    response = requests.get(f\"{API_BASE_URL}/api/jobs/{job_id}\")\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_job_status(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the process, you can define utility functions that:\n",
    "\n",
    "- Periodically retrieve the job status\n",
    "- Format the output into a table\n",
    "\n",
    "This makes it easier to compare and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def format_runtime(seconds):\n",
    "    \"\"\"Format runtime in seconds to a human-readable string.\"\"\"\n",
    "    if seconds is None:\n",
    "        return \"-\"\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    if minutes > 0:\n",
    "        return f\"{int(minutes)}m {int(seconds)}s\"\n",
    "    return f\"{int(seconds)}s\"\n",
    "\n",
    "def extract_main_score(score_str):\n",
    "    try:\n",
    "        first_score = score_str.split(\";\")[0]\n",
    "        value = first_score.split(\":\")[1].strip()\n",
    "        return float(value)\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "def create_results_table(job_data):\n",
    "    \"\"\"Create a pandas DataFrame from job data.\"\"\"\n",
    "    rows = []\n",
    "    for nim in job_data[\"nims\"]:\n",
    "        model_name = nim[\"model_name\"]\n",
    "        for eval in nim[\"evaluations\"]:\n",
    "            score_str = \"; \".join(f\"{k}: {v}\" for k, v in eval[\"scores\"].items() if k != \"function_name_and_args_accuracy\")\n",
    "            main_score = extract_main_score(score_str)\n",
    "            rows.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Eval Type\": eval[\"eval_type\"].upper(),\n",
    "                \"Score\": main_score,\n",
    "                \"Percent Done\": eval[\"progress\"],\n",
    "                \"Runtime\": format_runtime(eval[\"runtime_seconds\"]),\n",
    "                \"Status\": \"Completed\" if eval[\"finished_at\"] else \"Running\",\n",
    "                \"Started\": datetime.fromisoformat(eval[\"started_at\"]).strftime(\"%H:%M:%S\"),\n",
    "                \"Finished\": datetime.fromisoformat(eval[\"finished_at\"]).strftime(\"%H:%M:%S\") if eval[\"finished_at\"] else \"-\"\n",
    "            })\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"Model\", \"Eval Type\", \"Scores\", \"Percent Done\", \"Runtime\", \"Status\", \"Started\", \"Finished\"])\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    return df.sort_values([\"Model\", \"Eval Type\"])\n",
    "\n",
    "def create_customization_table(job_data):\n",
    "    \"\"\"Create a pandas DataFrame from customization data.\"\"\"\n",
    "    customizations = []\n",
    "    for nim in job_data[\"nims\"]:\n",
    "        model_name = nim[\"model_name\"]\n",
    "        for custom in nim[\"customizations\"]:\n",
    "            customizations.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Started\": datetime.fromisoformat(custom[\"started_at\"]).strftime(\"%H:%M:%S\"),\n",
    "                \"Epochs Completed\": custom[\"epochs_completed\"],\n",
    "                \"Steps Completed\": custom[\"steps_completed\"],\n",
    "                \"Finished\": datetime.fromisoformat(custom[\"finished_at\"]).strftime(\"%H:%M:%S\") if custom[\"finished_at\"] else \"-\",\n",
    "                \"Status\": \"Completed\" if custom[\"finished_at\"] else \"Running\",\n",
    "                \"Runtime\": format_runtime(custom[\"runtime_seconds\"]),\n",
    "                \"Percent Done\": custom[\"progress\"],\n",
    "            })\n",
    "   \n",
    "    if not customizations:\n",
    "        customizations = pd.DataFrame(columns=[\"Model\", \"Started\", \"Epochs Completed\", \"Steps Completed\", \"Finished\", \"Runtime\", \"Percent Done\"])\n",
    "    customizations = pd.DataFrame(customizations)\n",
    "    return customizations.sort_values([\"Model\"])\n",
    "\n",
    "def monitor_job(job_id):\n",
    "    \"\"\"Monitor a job and display its progress in a table.\"\"\"\n",
    "    print(f\"Monitoring job {job_id}...\")\n",
    "    print(\"Press Ctrl+C to stop monitoring\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            job_data = get_job_status(job_id)\n",
    "            results_df = create_results_table(job_data)\n",
    "            customizations_df = create_customization_table(job_data)\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Job Status: {job_data['status']}\")\n",
    "            print(f\"Total Records: {job_data['num_records']}\")\n",
    "            print(f\"Last Updated: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "            print(\"\\nResults:\")\n",
    "            display(results_df)\n",
    "            print(\"\\nCustomizations:\")\n",
    "            display(customizations_df)\n",
    "            display(job_data)\n",
    "\n",
    "            # Plot 1: Evaluation Scores\n",
    "            ax.set_title(\"Evalulation Results\", fontsize=14)\n",
    "            if not results_df.empty:\n",
    "                pivot_df = results_df.pivot(index=\"Model\", columns=\"Eval Type\", values=\"Score\").fillna(0)\n",
    "                pivot_df.plot(kind='bar', ax=ax)\n",
    "                ax.set_ylabel(\"Eval Metrics\")\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.legend(title=\"Eval Type\")\n",
    "                ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, \"No Evaluation Data\", ha='center', va='center')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()                        \n",
    "            time.sleep(POLL_INTERVAL)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nMonitoring stopped by user\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start monitoring the job\n",
    "monitor_job(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
