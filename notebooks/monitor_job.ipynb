{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Flywheel Blueprint Dev notebook\n",
    "\n",
    "This notebook uploads some sample data, runs a flywheel job and monitors its progress, displaying results in a table that updates as evaluations complete.\n",
    "\n",
    "## Rough architecture goal\n",
    "\n",
    "Below is our current rough goal for the architecture\n",
    "\n",
    "![Arch](./arch.png)\n",
    "\n",
    "## Current deployment for notebook\n",
    "\n",
    "Below is how this notebook is currently deployed\n",
    "\n",
    "![Deployment](./deployment.png)\n",
    "\n",
    "## Prerequisities\n",
    "\n",
    "Pull down this repo and do the following:\n",
    "\n",
    "Install deps:\n",
    "\n",
    "```sh\n",
    "uv sync --dev\n",
    "```\n",
    "\n",
    "Run docker compose:\n",
    "\n",
    "```sh\n",
    "docker compose up --build\n",
    "```\n",
    "\n",
    "Once the services are all up, continue with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit this next cell!\n",
    "\n",
    "Put the full absolute path of where you downloaded this git repo into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ABSOLUTE_PATH = \"/home/rangilly/code/data-flywheel-blueprint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define code snippets\n",
    "\n",
    "This section defines the methods we need in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch is ready! Status: yellow\n",
      "Elasticsearch is ready! Status: yellow\n",
      "Index already exists\n",
      "Index already exists\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)        # Width of the display in characters\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content of each cell\n",
    "\n",
    "# Add the parent directory of the current notebook to the Python path\n",
    "notebook_dir = os.path.join(PROJECT_ABSOLUTE_PATH, \"notebooks\")\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, os.pardir))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from src.scripts.load_test_data import load_data_to_elasticsearch\n",
    "\n",
    "# Configuration\n",
    "API_BASE_URL = \"http://0.0.0.0:8000\"\n",
    "WORKLOAD_ID = \"bug-triager\"\n",
    "CLIENT_ID = \"dev-notebook\"\n",
    "POLL_INTERVAL = 5  # seconds\n",
    "\n",
    "def get_job_status(job_id):\n",
    "    \"\"\"Get the current status of a job.\"\"\"\n",
    "    response = requests.get(f\"{API_BASE_URL}/api/jobs/{job_id}\")\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def format_runtime(seconds):\n",
    "    \"\"\"Format runtime in seconds to a human-readable string.\"\"\"\n",
    "    if seconds is None:\n",
    "        return \"-\"\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    if minutes > 0:\n",
    "        return f\"{int(minutes)}m {int(seconds)}s\"\n",
    "    return f\"{int(seconds)}s\"\n",
    "\n",
    "def create_results_table(job_data):\n",
    "    \"\"\"Create a pandas DataFrame from job data.\"\"\"\n",
    "    rows = []\n",
    "    for nim in job_data[\"nims\"]:\n",
    "        model_name = nim[\"model_name\"]\n",
    "        for eval in nim[\"evaluations\"]:\n",
    "            rows.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Eval Type\": eval[\"eval_type\"].upper(),\n",
    "                \"Score\": \"; \".join(f\"{k}: {v}\" for k, v in eval[\"scores\"].items()),\n",
    "                \"Percent Done\": eval[\"progress\"],\n",
    "                \"Runtime\": format_runtime(eval[\"runtime_seconds\"]),\n",
    "                \"Status\": \"Error\" if eval.get(\"error\", None) else \"Completed\" if eval[\"finished_at\"] else \"Running\",\n",
    "                \"Started\": datetime.fromisoformat(eval[\"started_at\"]).strftime(\"%H:%M:%S\"),\n",
    "                \"Finished\": datetime.fromisoformat(eval[\"finished_at\"]).strftime(\"%H:%M:%S\") if eval[\"finished_at\"] else \"-\"\n",
    "            })\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"Model\", \"Eval Type\", \"Scores\", \"Percent Done\", \"Runtime\", \"Status\", \"Started\", \"Finished\"])\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    return df.sort_values([\"Model\", \"Eval Type\"])\n",
    "\n",
    "def create_customization_table(job_data):\n",
    "    \"\"\"Create a pandas DataFrame from customization data.\"\"\"\n",
    "    customizations = []\n",
    "    for nim in job_data[\"nims\"]:\n",
    "        model_name = nim[\"model_name\"]\n",
    "        for custom in nim[\"customizations\"]:\n",
    "            customizations.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Started\": datetime.fromisoformat(custom[\"started_at\"]).strftime(\"%H:%M:%S\"),\n",
    "                \"Epochs Completed\": custom[\"epochs_completed\"],\n",
    "                \"Steps Completed\": custom[\"steps_completed\"],\n",
    "                \"Finished\": datetime.fromisoformat(custom[\"finished_at\"]).strftime(\"%H:%M:%S\") if custom[\"finished_at\"] else \"-\",\n",
    "                \"Status\": \"Error\" if custom.get(\"error\", None) else \"Completed\" if custom[\"finished_at\"] else \"Running\",\n",
    "                \"Runtime\": format_runtime(custom[\"runtime_seconds\"]),\n",
    "                \"Percent Done\": custom[\"progress\"],\n",
    "            })\n",
    "   \n",
    "    if not customizations:\n",
    "        customizations = pd.DataFrame(columns=[\"Model\", \"Started\", \"Epochs Completed\", \"Steps Completed\", \"Finished\", \"Runtime\", \"Percent Done\"])\n",
    "    customizations = pd.DataFrame(customizations)\n",
    "    return customizations.sort_values([\"Model\"])\n",
    "\n",
    "def monitor_job(job_id):\n",
    "    \"\"\"Monitor a job and display its progress in a table.\"\"\"\n",
    "    print(f\"Monitoring job {job_id}...\")\n",
    "    print(\"Press Ctrl+C to stop monitoring\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            job_data = get_job_status(job_id)\n",
    "            evals_df = create_results_table(job_data)\n",
    "            customizations_df = create_customization_table(job_data)\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Job Status: {job_data['status']}\")\n",
    "            # print(f\"Percent done: {job_data['progress']}\")\n",
    "            print(f\"Total Records: {job_data['num_records']}\")\n",
    "            print(f\"Last Updated: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "            print(\"\\nResults:\")\n",
    "            display(evals_df)\n",
    "            print(\"\\nCustomizations:\")\n",
    "            display(customizations_df)\n",
    "            \n",
    "            display(job_data)\n",
    "            \n",
    "            # if job_data[\"status\"] in [\"SUCCESS\", \"FAILURE\"]:\n",
    "            #     print(f\"\\nJob completed with status: {job_data['status']}\")\n",
    "            #     break\n",
    "                \n",
    "            time.sleep(POLL_INTERVAL)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nMonitoring stopped by user\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data\n",
    "\n",
    "For the purposes of this notebook, we have created a `bug_triage` dataset. This is a very simple dataset. It was created using llama-3.1-70b-instruct. It is not \"real\" nor is it \"good.\" You should not expect this dataset to yield any good results. It is purely illustrative to allow the flywheel to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document is already in the log format. Loading with overrides.\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# workload_id = \"test\"\n",
    "# load_data_to_elasticsearch(workload_id, CLIENT_ID, \"test_test_data.jsonl\")\n",
    "\n",
    "# load_data_to_elasticsearch(\"\", CLIENT_ID, \"aiva_dataset.jsonl\")\n",
    "\n",
    "load_data_to_elasticsearch(\"aiva_1\", \"dev\", \"aiva-final.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the flywheel and monitor\n",
    "\n",
    "Kick off the flyhweel job. The service currently requires that you manually tell it to run a flywheel for a given `workload_id`. Automating this is trivial,\n",
    "but first principles dictate we first give customers the ability to run these when they want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job with ID: 68276ed8501f0a49988c56f7\n"
     ]
    }
   ],
   "source": [
    "# Create a new job\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{API_BASE_URL}/api/jobs\",\n",
    "    json={\"workload_id\": \"aiva_1\", \"client_id\": \"dev\"}\n",
    ")\n",
    "\n",
    "response.raise_for_status()\n",
    "job_id = response.json()[\"id\"]\n",
    "\n",
    "print(f\"Created job with ID: {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start monitoring the job\n",
    "monitor_job(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    f\"{API_BASE_URL}/api/jobs\",\n",
    "    json={\"workload_id\": \"aiva_3\", \"client_id\": \"3434\"}\n",
    ")\n",
    "\n",
    "response.raise_for_status()\n",
    "job3_id = response.json()[\"id\"]\n",
    "\n",
    "print(f\"Created job with ID: {job3_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_job(job3_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
